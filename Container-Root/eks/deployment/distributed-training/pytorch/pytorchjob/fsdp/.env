#!/bin/bash

# Configuration for FSDP jobs

## AWS
export AWS_REGION=us-west-2
export ACCOUNT=$(aws sts get-caller-identity --query Account --output text)

## Docker Image
export REGISTRY=${ACCOUNT}.dkr.ecr.${AWS_REGION}.amazonaws.com/
export IMAGE=fsdp
## DOCKERFILE_EXT=nanogpt-sockets|nanogpt-efa|llama2-sockets|llama2-efa|llama2-efa-dlc
export DOCKERFILE_EXT=llama3-vision-efa-dlc
export TAG=":${DOCKERFILE_EXT}"

## FSDP Job
export JOB_NAME=fsdp
export RDZV_HOST=etcd
export RDZV_PORT=2379
## NUM_WORKERS - Default 2, set to number of worker nodes
export NUM_WORKERS=2
## EFA_PER_WORKER - Default 0, number of EFA adapters per node. For G4dn.metal this is 1, for P4 use 4, for P5 use 32
export EFA_PER_WORKER=32
## GPU_PER_WORKER - number of GPUs per worker, the number of GPUs for the selected instance type.
export GPU_PER_WORKER=8
## INSTANCE_TYPE=p4de.24xlarge|p5.48xlarge|g4dn.metal|g4dn.8xlarge(default)|etc
export INSTANCE_TYPE=p5.48xlarge
## FI_PROVIDER=sockets(default)|efa
export FI_PROVIDER=efa

## Model
## Support is available for NanoGPT and Llama2. Only one of the sections below should be uncommented and should match the DOCKERFILE_EXT section above

## Llama2
## Register at Huggingface and get a token by visiting: https://huggingface.co/docs/hub/security-tokens, then insert your token here
export HF_TOKEN="<insert_your_huggingface_token_here>"
## Llama3.2 MODEL_NAME=meta-llama/Llama-3.2-11B-Vision-Instruct
export MODEL_NAME=meta-llama/Llama-3.2-11B-Vision-Instruct
## Llama3.2 train command
export CMD="huggingface-cli login --token ${HF_TOKEN} && \
torchrun --nnodes ${NUM_WORKERS} --nproc_per_node ${GPU_PER_WORKER}  \
recipes/quickstart/finetuning/finetuning.py --enable_fsdp --lr 1e-5  --num_epochs 5 --batch_size_training 2 \
--model_name ${MODEL_NAME} \
--dist_checkpoint_root_folder ./finetuned_model_mind2web \
--dist_checkpoint_folder fine-tuned  --use_fast_kernels \
--dataset custom_dataset --custom_dataset.test_split test \
 --custom_dataset.file /workspace/llama-recipes/recipes/quickstart/finetuning/datasets/multimodal_mind2web_dataset.py \  
 --run_validation True --batching_strategy padding "
